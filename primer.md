# CloudEvents Primer - Version 1.0

## Abstract

This non-normative document provides an overview of the CloudEvents
specification. It is meant to complement the CloudEvent specification to provide
additional background and insight into the history and design decisions made
during the development of the specification. This allows the specification
itself to focus on the normative technical details.

## Status of this document

This document is a working draft.

## Table of Contents

- [History](#history)
- [CloudEvents Concepts](#cloudevents-concepts)
- [Design Goals](#design-goals)
- [Architecture](#architecture)
- [Versioning of Attributes](#versioning-of-attributes)
- [CloudEvent Attributes](#cloudevent-attributes)
- [CloudEvent Attribute Extensions](#cloudevent-attribute-extensions)
- [Creating CloudEvents](#creating-cloudevents)
- [Qualifying Protocols and Encodings](#qualifying-protocols-and-encodings)
- [Proprietary Protocols and Encodings](#proprietary-protocols-and-encodings)
- [Prior Art](#prior-art)
- [Roles](#roles)
- [Value Proposition](#value-proposition)
- [Existing Event Formats](#existing-event-formats)

## History

The [CNCF Serverless Working group](https://github.com/cncf/wg-serverless) was
originally created by the CNCF's
[Technical Oversight Committee](https://github.com/cncf/toc) to investigate
Serverless Technology and to recommend some possible next steps for some CNCF
related activities in this space. One of the recommendations was to investigate
the creation of a common event format to aid in the portability of functions
between Cloud providers and the interoperability of processing of event streams.
As a result, the CloudEvents specification was created.

While initially the work on CloudEvents was done as part of the Serverless
Working group, once the specification reached its v0.1 milestone, the TOC
approved the CloudEvents work as a new stand-alone CNCF sandbox project.

## CloudEvents Concepts

An [event](spec.md#event) includes context and data about an
[occurrence](spec.md#occurrence). Each _occurrence_ is uniquely identified by
the data of the _event_.

_Events_ represent facts and therefore do not include a destination, whereas
messages convey intent, transporting data from a source to a given destination.

### Eventing

Events are commonly used in server-side code to connect disparate systems where
the change of state in one system causes code to execute in another. For
example, a source may generate an event when it receives an external signal
(e.g. HTTP or RPC) or observes a changing value (e.g. an IoT sensor or period of
inactivity).

To illustrate how a system uses CloudEvents, the simplified diagram below shows
how an event from a [source](spec.md#source) triggers an action.

![alt text](source-event-action.png "A box representing the source with
arrow pointing to a box representing the action. The arrow is annotated with
'e' for event and 'protocol'.")

The source generates a message where the event is encapsulated in a protocol.
The event arrives to a destination, triggering an action which is provided with
the event data.

A _source_ is a specific instance of a source-type which allows for staging and
test instances. Open source software of a specific _source-type_ may be deployed
by multiple companies or providers.

Events can be delivered through various industry standard protocols (e.g. HTTP,
AMQP, MQTT, SMTP), open-source protocols (e.g. Kafka, NATS), or platform/vendor
specific protocols (AWS Kinesis, Azure Event Grid).

An action processes an event defining a behavior or effect which was triggered
by a specific _occurrence_ from a specific _source_. While outside of the scope
of the specification, the purpose of generating an _event_ is typically to allow
other systems to easily react to changes in a source that they do not control.
The _source_ and action are typically built by different developers. Often the
_source_ is a managed service and the _action_ is custom code in a serverless
Function (such as AWS Lambda or Google Cloud Functions).

## Design Goals

CloudEvents are typically used in a distributed system to allow for services to
be loosely coupled during development, deployed independently, and later can be
connected to create new applications.

The goal of the CloudEvents specification is to define interoperability of event
systems that allow services to produce or consume events, where the producer and
consumer can be developed and deployed independently. A producer can generate
events before a consumer is listening, and a consumer can express an interest in
an event or class of events that is not yet being produced. Note that the
specifications produced by this effort are focused on interoperability of the
event format and how it appears while being sent on various protocols, such as
HTTP. The specifications will not focus on the processing model of either the
event producer or event consumer.

CloudEvents, at its core, defines a set of metadata, called attributes, about
the event being transferred between systems, and how those pieces of metadata
should appear in that message. This metadata is meant to be the minimal set of
information needed to route the request to the proper component and to
facilitate proper processing of the event by that component. So, while this
might mean that some of the application data of the event itself might be
duplicated as part of the CloudEvent's set of attributes, this is to be done
solely for the purpose of proper delivery, and processing, of the message. Data
that is not intended for that purpose should instead be placed within the event
(`data`) itself.

Additionally, it is assumed that the metadata needed by the protocol layer to
deliver the message to the target system is handled entirely by the protocol
and therefore is not included within the CloudEvents attributes. See the
[Non-Goals](#non-goals) section for more details.

Along with the definition of these attributes, there will also be specifications
of how to serialize the event in different formats (e.g. JSON) and protocols
(e.g. HTTP, AMQP, Kafka).

Batching of multiple events into a single API call is natively supported by some
protocols. To aid interoperability, it is left up to the protocols if and how
batching is implemented. Details may be found in the protocol binding or in the
protocol specification. A batch of CloudEvents carries no semantic meaning and
is not ordered. An [Intermediary](spec.md#intermediary) can add or remove
batching as well as assign events to different batches.

### Non-Goals

The following are considered beyond the scope of the specification:

- Function build and invocation process
- Language-specific runtime APIs
- Selecting a single identity/access control system
- Inclusion of protocol-level routing information
- Event persistence processes

The CloudEvents spec will not include protocol-level routing information (e.g.
a destination URL to which the event is being sent). This is a common suggestion
by those new to the concepts of CloudEvents. After much deliberation, the
working group has come to the conclusion that routing is unnecessary in the
spec: any protocol (e.g. HTTP, MQTT, XMPP, or a Pub/Sub bus) already
defines semantics for routing. For example, the CloudEvents
[HTTP binding](http-protocol-binding.md) dictates headers and request body
contents. CloudEvents don't need to include a destination URL in the spec to be
HTTP compatible; the HTTP spec already includes one in the
[Request-Line](https://tools.ietf.org/html/rfc2616#section-5.1).

Routing information is not just redundant, it detracts. CloudEvents should
increase interoperability and decouple the producer and consumer of events.
Prohibiting routing information from the events format allows CloudEvents to be
redelivered to new actions, or to be delivered over complex relays that include
multiple channels. For example, a CloudEvent that was intended for a webhook
should be deliverable to a dead-letter queue if the webhook address is
unavailable. That dead-letter queue should be able to feed events to new actions
that the original event emitter never imagined.

The CloudEvents that are produced and consumed within and across systems trigger
behaviors that derive value. As such, archiving and/or replaying events can be
valuable for debugging or replication purposes. However, persisting an event
removes the contextual information available during transmission such as the
identity and rights of the producer, fidelity validation mechanisms, or
confidentiality protections. Additionally, persistence can add complexity and
challenge to meeting user's requirements. For example, the repeated use of a
private key for encryption or signing purposes increases the information
available to attackers and thereby reduces security. It is expected that
attributes may be defined that facilitate meeting persistence requirements but
it is expected that these will continuously evolve along with industry best
practices and advancements.

## Architecture

The CloudEvents specification set defines four different kinds of protocol
elements that form a layered architecture model.

1. The [base specification](spec.md) defines an abstract information model made
   up of attributes (key-value pairs) and associated rules for what constitutes
   a CloudEvent.
2. The [extensions](./spec.md#extension-context-attributes) add use-case
   specific and potentially overlapping sets of extension attributes and
   associated rules, e.g. to support different tracing standards.
3. The event format encodings, e.g. [JSON](json-format.md), define how the
   information model of the base specification together with the chosen
   extensions is encoded for mapping it to header and payload elements of an
   application protocol.
4. The protocol bindings, e.g. [HTTP](http-protocol-binding.md), defines how
   the CloudEvent is bound to an application protocol's transport frame, in the
   case of HTTP to the HTTP message. The protocol binding does not constrain
   how the transport frame is used, meaning that the HTTP binding can be used
   with any HTTP method and with request and response messages.

If required to assure broader interoperability, the CloudEvents specification
set will provide specific constraints for event delivery using a particular
application protocol. The [HTTP Webhook](http-webhook.md) specification is not
specific to CloudEvents and can be used to post any kind of one-way event and
notifications to a conformant HTTP endpoint. However, the lack of such a
specification elsewhere makes it necessary for CloudEvents to define it.

### Interoperability Constraints

As stated in the [Design Goals](#design-goals) section, interoperability is
a key objective of the specification. Therefore, there are places in the
specification where restrictions are recommended. For example, in the
[Size Limits](./spec.md#size-limits) section it hints that event sizes should
not exceed 64KB. It is important to note that constraints such as these,
where they are not mandated via a "MUST", are recommendations to increase
the likelihood of interoperability between multiple implementations and
deployments. Specific uses of the specification are free to ignore these
recommendations but it is incumbent on those environments to ensure that all
components involved in the delivery of the CloudEvents are able to
leave the boundaries of the recommendations.

### Protocol Error Handling

The CloudEvents specification, for the most part, does not dictate a processing
model associated with the creation or processing of CloudEvents. As such, if
there are errors during the processing of a CloudEvent, the software
encountering the error is encouraged to use the normal protocol-level error
reporting to report them.

## Versioning of Attributes

For certain CloudEvents attributes, the entity or data model referenced by its
value might change over time. For example, `dataschema` might reference one
particular version of a schema document. Often these attribute values will then
distinguish each variant by including some version-specific string as part of
its value. For example, a version number (`v1`, `v2`), or a date (`2018-01-01`)
might be used.

The CloudEvents specification does not mandate any particular pattern to be
used, or even the use of version strings at all. This decision is up to each
event producer. However, when a version-specific string is included, care should
be taken whenever its value changes as event consumers might be reliant on the
existing value and thus a change could be interpreted as a "breaking change".
Some form of communication between producers and consumers should be established
to ensure the event consumers know what possible values might be used. In
general, this is true for all CloudEvents attributes as well.

## CloudEvent Attributes

This section provides additional background and design points related to some of
the CloudEvent attributes.

### id

The `id` attribute is meant to be a value that is unique across all events
related to one event source (where each event source is uniquely identified by
its CloudEvents `source` attribute value). While the exact value used is
producer defined, receivers of CloudEvents from a single event source can be
assured that no two events will share the same `id` value. We are implicitly
making a claim here that no two events will share the same `id` value, but do 
not provide an explanation as to how this is guaranteed, since this is out of
the scope of this spec. The only exception to
this is if some replay of the event is supported, and in those cases, the `id`
can then be used to detect this.

Since a single occurrence may result in the generation of more than one event,
in the cases where all of those events are from the same event source, each
CloudEvent constructed will have a unique `id`. Take the example of the creation
of a DB entry, this one occurrence might generate a CloudEvent with a type of
`create` and a CloudEvent with a type of `write`. Each of those CloudEvents
would have a unique `id`. If there is the desire for some correlation between
those two CloudEvents to indicate they are both related to the same occurrence,
then some additional data within the CloudEvent would be used for that purpose.

In this respect, while the exact value chosen by the event producer might be
some random string, or a string that has some semantic meaning in some other
context, for the purposes of this CloudEvent attribute those meanings are not
relevant and therefore using `id` for some other purpose beyond uniqueness
checking is out of scope of the specification and not recommended.

## CloudEvent Attribute Extensions

In order to achieve the stated goals, the specification authors will attempt to
constrain the number of metadata attributes they define in CloudEvents. To that
end, attributes defined by this project will fall into three categories:

- required
- optional
- extensions

As the category names imply, "required" attributes will be the ones that the
group considers vital to all events in all use cases, while "optional" ones will
be used in a majority of the cases. Both of the attributes in these cases will
be defined within the specification itself.

When the group determines that an attribute is not common enough to fall into
those two categories but would still benefit from the level of interoperability
that comes from being well-defined, then they will be placed into the
"extensions" category and put into
[documented extensions](documented-extensions.md). The specification defines how
these extension attributes will appear within a CloudEvent.

In determining which category a proposed attribute belongs, or even if it will
be included at all, the group uses use-cases and user-stories to explain the
rationale and need for them. This supporting information will be added to the
[Prior Art](#prior-art) section of this document.

Extension attributes to the CloudEvent specification are meant to be additional
metadata that needs to be included to help ensure proper routing and processing
of the CloudEvent. Additional metadata for other purposes, that is related to
the event itself and not needed in the transportation or processing of the
CloudEvent, should instead be placed within the proper extensibility points of
the event (`data`) itself.

Extension attributes should be kept minimal to ensure the CloudEvent can be
properly serialized and transported. For example, the Event producers should
consider the technical limitations that might be encountered when adding
extensions to a CloudEvent. For example, the
[HTTP Binary Mode](http-protocol-binding.md#31-binary-content-mode) uses HTTP
headers to transport metadata; most HTTP servers will reject requests with
excessive HTTP header data, with limits as low as 8kb. Therefore, the aggregate
size and number of extension attributes should be kept minimal.

If an extension becomes popular then the specification authors might consider
moving it into the specification as a core attribute. This means that the
extension mechanism/process can be used as a way to vet new attributes prior to
formally adding them to the specification.

### JSON Extensions

As mentioned in the [Attributes](json-format.md#2-attributes) section of the
[JSON Event Format for CloudEvents](json-format.md) specification, CloudEvent
extension attributes are serialized as siblings to the specification defined
attributes - meaning, at the top-level of the JSON object. The authors of the
specification spent a long time considering all options and decided that this
was the best choice. Some of the rationale follows.

Since the specifications follow [semver](https://semver.org/), this means that
new properties can be defined by future versions of the core specification
without requiring a major version number change - as long as these properties
are optional. In those cases, consider what an existing consumer would do with a
new (unknown) top-level property. While it would be free to ignore it, since it
is optional, in most cases it is believed that these properties would still want
to be exposed to the application receiving those events. This would allow those
applications to support these properties even if the infrastructure doesn't.
This means that unknown top-level properties (regardless of who defined them -
future versions of the spec or the event producer) are probably not going to be
ignored. So, while some other specifications define a specific property under
which extensions are placed (e.g. a top-level `extensions` property), the
authors decided that having two different locations within an incoming event for
unknown properties could lead to interoperability issues and confusion for
developers.

Often extensions are used to test new potential properties of specifications
prior to them being formally adopted. If there were an `extensions` type of
property, in which this new property was serialized, then if that property were
to ever be adopted by the core specification it would be promoted (from a
serialization perspective) from the `extensions` property to be a top-level
property. If we assume that this new property will be optional, then as it is
adopted by the core specification it will be just a minor version increment, and
all existing consumers should still continue to work. However, consumers will
not know where this property will appear - in the `extensions` property or as a
top-level property. This means they might need to look in both places. What if
the property appears in both place but with different values? Will producers
need to place it in both places since they could have old and new consumers?
While it might be possible to define clear rules for how to solve each of the
potential problems that arise, the authors decided that it would be better to
simply avoid all of them in the first place by only having one location in the
serialization for unknown, or even new, properties. It was also noted that the
HTTP specification is now following a similar pattern by no longer suggesting
that extension HTTP headers be prefixed with `X-`.

## Creating CloudEvents

The CloudEvents specification purposely avoids being too prescriptive about how
CloudEvents are created. For example, it does not assume that the original event
source is the same entity that is constructing the associated CloudEvent for
that occurrence. This allows for a wide variety of implementation choices.
However, it can be useful for implementors of the specification to understand
the expectations that the specification authors had in mind as this might help
ensure interoperability and consistency.

As mentioned above, whether the entity that generated the initial event is the
same entity that creates the corresponding CloudEvent is an implementation
choice. However, when the entity that is constructing/populating the CloudEvents
attributes is acting on behalf of the event source, the values of those
attributes are meant to describe the event or the event source and not the
entity calculating the CloudEvent attribute values. In other words, when the
split between the event source and the CloudEvents producer are not materially
significant to the event consumers, the spec defined attributes would typically
not include any values to indicate this split of responsibilities.

This isn't to suggest that the CloudEvents producer couldn't add some additional
attributes to the CloudEvent, but those are outside the scope of the
interoperability defined attributes of the spec. This is similar to how an HTTP
proxy would typically minimize changes to the well-defined HTTP headers of an
incoming message, but it might add some additional headers that include
proxy-specific metadata.

It is also worth noting that this separation between original event source and
CloudEvents producer could be small or large. Meaning, even if the CloudEvent
producer were not part of the original event source's ecosystem, if it is acting
on behalf of the event source, and its presence in the flow of the event is not
meaningful to event consumers, then the above guidance would still apply.

When an entity is acting as both a receiver and sender of CloudEvents for the
purposes of forwarding, or transforming, the incoming event, the degree to which
the outbound CloudEvent matches the inbound CloudEvent will vary based on the
processing semantics of this entity. In cases where it is acting as proxy, where
it is simply forwarding CloudEvents to another event consumer, then the outbound
CloudEvent will typically look identical to the inbound CloudEvent with respect
to the spec defined attributes - see previous paragraph concerning adding
additional attributes.

However, if this entity is performing some type of semantic processing of the
CloudEvent, typically resulting in a change to the value of the `data`
attribute, then it may need to be considered a distinct "event source" from the
original event source. And as such, it is expected that CloudEvents attributes
related to the event producer (such as `source` and `id`) would be changed from
the incoming CloudEvent.

There might exist special cases in which it is necessary to create a CloudEvent
that contains another CloudEvent. Although the specification does not define
nesting explicitly, it is possible. While the inner event will always be encoded
in a [stand-alone event format](spec.md#event-format), the outer event can be
either binary or structured mode. The `datacontenttype` attribute of the outer
event must not be set to `application/cloudevents+json` or any other media type
that is used to denote the usage of structured mode. A correct example of event
nesting would be:

```
Content-Type: application/json
ce-specversion: 1.0
ce-type: myevent
ce-id: 1234-1234-1234
ce-source: example.com

{
  "specversion": "1.0",
  "type": "coolevent",
  "id": "xxxx-xxxx-xxxx",
  "source": "bigco.com",
  "data": { ... }
}
```

## Qualifying Protocols and Encodings

The explicit goal of the CloudEvents effort, as expressed in the specification,
is "describing event data in a common way" and "to define interoperability of
event systems that allow services to produce or consume events, where the
producer and consumer can be developed and deployed independently".

The foundations for such interoperability are open data formats and open
protocols, with CloudEvents aiming to provide such an open data format and
projections of its data format onto commonly used protocols and with commonly
used encodings.

While each software or service product and project can obviously make its own
choices about which form of communication it prefers, its unquestionable that a
proprietary protocol that is private to such a product or project does not
further the goal of broad interoperability across producers and consumers of
events.

Especially in the area of messaging and eventing, the industry has made
significant progress in the last decade in developing a robust and broadly
supported protocol foundation, like HTTP 1.1 and HTTP/2 as well as WebSockets or
events on the web, or MQTT and AMQP for connection-oriented messaging and
telemetry transfers.

Some widely used protocols have become de-facto standards emerging out of strong
ecosystems of top-level consortia of three or more companies, and some out of
the strong ecosystems of projects released by a single company, and in either
case largely in parallel to the evolution of the previously mentioned standards
stacks.

The CloudEvents effort shall not become a vehicle to even implicitly endorse or
promote project- or product-proprietary protocols, because that would be
counterproductive towards CloudEvents' original goals.

For a protocol or encoding to qualify for a core CloudEvents event format or
protocol binding, it must belong to either one of the following categories:

- The protocol has a formal status as a standard with a widely-recognized
  multi-vendor protocol standardization body (e.g. W3C, IETF, OASIS, ISO)
- The protocol has a "de-facto standard" status for its ecosystem category,
  which means it is used so widely that it is considered a standard for a given
  application. Practically, we would like to see at least one open source
  implementation under the umbrella of a vendor-neutral open-source organization
  (e.g. Apache, Eclipse, CNCF, .NET Foundation) and at least a dozen independent
  vendors using it in their products/services.

Aside from formal status, a key criterion for whether a protocol or encoding
shall qualify for a core CloudEvents event format or protocol binding is
whether the group agrees that the specification will be of sustained practical
benefit for any party that is unrelated to the product or project from which the
protocol or encoding emerged. A base requirement for this is that the protocol
or encoding is defined in a fashion that allows alternate implementations
independent of the product or project's code.

All other protocol and encoding formats for CloudEvents are welcome to be
included in a list pointing to the CloudEvents binding information in the
respective project's own public repository or site.

## Proprietary Protocols and Encodings

To encourage adoption of CloudEvents, this repository will collect CloudEvent
specs for proprietary protocols and encodings without endorsement. Repository
maintainers are not responsible for creating, maintaining, or notifying
maintainers of proprietary specs of drift from the CloudEvents spec.

Proprietary specs will be hosted in their own repository or documentation site,
and collected in the [proprietary-specs](proprietary-specs.md) file. Proprietary
specs should follow the same format as the other specs for core protocols and
encodings.

Proprietary specs will receive less scrutiny than a core spec, and as the
CloudEvents spec evolves, it is the responsibility of the maintainers of the
respective protocols and encodings to keep specs in sync with the CloudEvents
spec. If a proprietary spec falls too far out of date, CloudEvents may mark the
link to that spec as deprecated or remove it.

In the case that multiple, incompatible specs are created for the same protocol,
the repository maintainers will be agnostic about which spec is correct and list
links to all specs.

## Prior Art

This section describes some of the input material used by the group during the
development of the CloudEvent specification.

### Roles

The list below enumerates the various participants, and scenarios, that might be
involved in the producing, managing or consuming of events.

In these, the roles of event producer and event consumer are kept distinct. A
single application context can always take on multiple roles concurrently,
including being both a producer and a consumer of events.

1. Applications produce events for consumption by other parties. Examples of
   this include: providing consumers with insights about end-user activities, state
   changes or environment observations, or for allowing complementing the
   application's capabilities with event-driven extensions.

   Events are typically produced related to a context or a producer-chosen
   classification. For example, a temperature sensor in a room might be
   context-qualified by mount position, room, floor, and building. A sports
   result(event) might be classified by league and team.

   The producer application could run anywhere, such as on a server or a device.

   The produced events might be rendered and emitted directly by the producer or
   by an intermediary; as example for the latter, consider event data
   transmitted by a device over payload-size-constrained networks such as
   LoRaWAN or ModBus, and where events compliant to this specification will be
   rendered by a network gateway on behalf of the producer.

   For example, a weather station transmits a 12-byte, proprietary event payload
   indicating weather conditions once every 5 minutes over LoRaWAN. A LoRaWAN
   gateway is then used to publish the event to an Internet destination in the
   CloudEvents format. The LoRaWAN gateway is the event producer, publishing on
   behalf of the weather station, and will set event metadata appropriately to
   reflect the source of the event.

2. Applications consume events for the purposes such as display, archival,
   analytics, workflow processing, monitoring the condition and/or providing
   transparency into the operation of a business solution and its foundational
   building blocks.

   The consumer application could run anywhere, such as on a server or a device.

   A consuming application will typically be interested in:

   - distinguishing events such that the exact same event is not processed
     twice.
   - identifying and selecting the origin context or the producer-assigned
     classification.
   - identifying the temporal order of the events relative to the originating
     context and/or relative to a wall-clock.
   - understanding the context-related detail information carried in the event.
   - correlating event instances from multiple event producers and send them to
     the same consumer context.

   In some cases, the consuming application might be interested in:

   - obtaining further details about the event's subject from the originating
     context, like obtaining detail information about a changed object that
     requires privileged access authorization. For example, a HR solution might
     only publish very limited information in events for privacy reasons, and
     any event consumer needing more data will have to obtain details related to
     the event from the HR system under their own authorization context.
   - interact with the event's subject at the originating context, for instance
     reading a storage blob after having been informed that this blob has just
     been created.

   Consumer interests motivate requirements for which information producers
   ought to include an event.

3. Middleware routes events from producers to consumers, or onwards to other
   middleware. Applications producing events might delegate certain tasks
   arising from their consumers' requirements to middleware:

   - Management of many concurrent interested consumers for one of multiple
     classes or originating contexts of events
   - Processing of filter conditions over a class or originating context of
     events on behalf of consumers.
   - Transcoding, like encoding in MsgPack after decoding from JSON
   - Transformation that changes the event's structure, like mapping from a
     proprietary format to CloudEvents, while preserving the identity and
     semantic integrity of the event.
   - Instant "push-style" delivery to interested consumers.
   - Storing events for eventual delivery, either for pick-up initiated by the
     consumer ("pull") or initiated by the middleware ("push") after a delay.
   - Observing event content or event flow for monitoring or diagnostics
     purposes.

   To satisfy these needs, middleware will be interested in:

   - A metadata discriminator, usable for classification or contextualization of
     events so that consumers can express interest in one or multiple such
     classes or contexts. For instance, a consumer might be interested in all
     events related to a specific directory inside a file storage account.
   - A metadata discriminator, that allows distinguishing the subject of a
     particular event of that class or context. For instance, a consumer might
     want to filter out all events related to new files ending with ".jpg" (the
     file name being the "new file" event's subject) for the purpose of describing
     a specific directory inside a file storage account that it has registered
     interest on.
   - An indicator for the encoding of the event and its data.
   - An indicator for the structural layout (schema) for the event and its data.

   Whether its events are available for consumption via a middleware is a
   delegation choice of the producer.

   In practice, middleware can take on the role of a
   [Producer](spec.md#producer) when it changes the semantic meaning of an
   event, a [Consumer](spec.md#consumer) when it takes action based on an event,
   or [Intermediary](spec.md#intermediary) when it routes events without making
   semantic changes.

4. Frameworks and other abstractions make interactions with the event platform
   infrastructure simpler, and often expose common API surface areas for
   other event platform infrastructures.

   Frameworks are often used for turning events into an object graph, and to
   dispatch the event to some specific handling user-code or user-rule that
   permits the consuming application to react to a particular kind of occurrence
   in the originating context and on a particular subject.

   Frameworks are most interested in semantic metadata commonality across the
   platforms they abstract, so that similar activities can be handled uniformly.

   For a sports application, a developer using the framework might be interested
   in all events from today's game (subject) of a team in a league (topic of
   interest) but wanting to handle reports of "goal" differently than reports of
   "substitution". For this, the framework will need a suitable metadata
   discriminator that frees it from having to understand the event details. To be 
   clear, the suitable metadata discriminator should be populated by the producer,
   and would not be the responsibility of the framework. 

### Value Proposition

This section describes some of the use-cases that explain the value of
CloudEvents.

#### Normalizing Events Across Services & Platforms

Major event publishers, (e.g. AWS, Microsoft, Google, etc.) publish events in
different formats on their respective platforms. There are even a few cases
where services on the same provider publish events in different formats (e.g.
AWS). This forces event consumers to implement custom logic to read or munge
event data across platforms and occasionally across services on a single
platform.

CloudEvents can offer a single experience for authoring consumers that handle
events across all platforms and services.

#### Facilitating Integrations Across Services & Platforms

Event data being transported across environments is increasingly common.
However, without a common way of describing events, delivery of events across
environments is hindered. There is no single way of determining where an event
came from and where it might be going. This prevents tooling to facilitate
successful event delivery and consumers from knowing what to do with event data.

CloudEvents offers useful metadata which middleware and consumers can rely upon
to facilitate event routing, logging, delivery and receipt.

#### Increasing Portability of Functions-as-a-Service

Functions-as-a-Service (also known as serverless computing) is one of the
fastest growing trends in IT and it is largely event-driven. However, a primary
concern of FaaS is vendor lock-in. This lock-in is partially caused by
differences in function APIs and signatures across providers, but the lock-in is
also caused by differences in the format of event data received within
functions.

CloudEvents' common way of describing event data increases the portability of
Functions-as-a-Service.

#### Improving Development & Testing of Event-Driven/Serverless Architectures

The lack of a common event format complicates development and testing of
event-driven and serverless architectures. There is no easy way to mock events
accurately for development and testing purposes, and help emulate event-driven
workflows in a development environment.

CloudEvents can enable better developer tools for building, testing and handling
the end-to-end lifecycle of event-driven and serverless architectures.

#### Event Data Evolution

Most platforms and services version the data model of their events differently
(if they do this at all). This creates an inconsistent experience for publishing
and consuming the data model of events as those data models evolve.

CloudEvents can offer a common way to version and evolve event data. This will
help event publishers safely version their data models based on best practices,
and this help event consumers safely work with event data as it evolves.

#### Normalizing Webhooks

Webhooks is a style of event publishing which does not use a common format.
Consumers of webhooks don’t have a consistent way to develop, test, identify,
validate, and overall process event data delivered via webhooks.

CloudEvents can offer consistency in webhook publishing and consumption.

#### Policy Enforcement

The transiting of events between systems may need to be filtered, transformed,
or blocked due to security and policy concerns. Examples may be to prevent
ingress or egress of the events such as event data containing sensitive
information or wanting to disallow the information flow between the sender and
receiver.

A common event format would allow easier reasoning about the data being
transited and allow for better introspection of the data.

#### Event Tracing

An event sent from a source may result in a sequence of additional events sent
from various middleware devices such as event brokers and gateways. CloudEvents
includes metadata in events to associate these events as being part of an event
sequence for the purpose of event tracing and troubleshooting.

#### IoT

IoT devices send and receive events related to their functionality. For example,
a connected thermostat will send telemetry on the current temperature and could
receive events to change temperatures. These devices typically have a
constrained operating environment (cpu, memory) requiring a well-defined event
message format. In a lot of cases these messages are binary encoded instead of
textual. Whether directly from the device or transformed via a gateway,
CloudEvents would allow for a better description of the origin of the message
and the format of the data contained within the message.

#### Event Correlation

A serverless application/workflow could be associated with multiple events from
different event sources/producers. For example, a burglary detection
application/workflow could involve both a motion event and a door/window open
event. A serverless platform could receive many instances of each type of
events, e.g. it could receive motion events and window open events from
different houses.

The serverless platform needs to correlate one type of event instance correctly
with other types of event instances and map a received event instance to the
correct application/workflow instance. CloudEvents will provide a standard way
for any event consumer (e.g. the serverless platform) to locate the event
correlation information/token in the event data and map a received event
instance to the correct application/workflow instance.

### Existing Event Formats

As with the previous section, the examination (and understanding) of the current
state of the world was very important to the group. To that end, a sampling of
existing current event formats that are used in practice today was gathered.

#### Microsoft - Event Grid

```json
{
  "topic": "/subscriptions/{subscription-id}",
  "subject": "/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.EventGrid/eventSubscriptions/LogicAppdd584bdf-8347-49c9-b9a9-d1f980783501",
  "eventType": "Microsoft.Resources.ResourceWriteSuccess",
  "eventTime": "2017-08-16T03:54:38.2696833Z",
  "id": "25b3b0d0-d79b-44d5-9963-440d4e6a9bba",
  "data": {
    "authorization": "{azure_resource_manager_authorizations}",
    "claims": "{azure_resource_manager_claims}",
    "correlationId": "54ef1e39-6a82-44b3-abc1-bdeb6ce4d3c6",
    "httpRequest": "",
    "resourceProvider": "Microsoft.EventGrid",
    "resourceUri": "/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.EventGrid/eventSubscriptions/LogicAppdd584bdf-8347-49c9-b9a9-d1f980783501",
    "operationName": "Microsoft.EventGrid/eventSubscriptions/write",
    "status": "Succeeded",
    "subscriptionId": "{subscription-id}",
    "tenantId": "72f988bf-86f1-41af-91ab-2d7cd011db47"
  }
}
```

[Documentation](https://docs.microsoft.com/en-us/azure/event-grid/event-schema)

#### Google - Cloud Functions (potential future)

```json
{
  "data": {
    "@type": "types.googleapis.com/google.pubsub.v1.PubsubMessage",
    "attributes": {
      "foo": "bar"
     },
     "messageId": "12345",
     "publishTime": "2017-06-05T12:00:00.000Z",
     "data": "somebase64encodedmessage"
  },
  "context": {
    "eventId": "12345",
    "timestamp": "2017-06-05T12:00:00.000Z",
    "eventTypeId": "google.pubsub.topic.publish",
    "resource": {
      "name": "projects/myProject/topics/myTopic",
      "service": "pubsub.googleapis.com"
    }
  }
}
```

#### AWS - CloudWatch Events

A high proportion of event-processing systems on AWS are converging on the use
of this format.

```json
{
  "version": "0",
  "id": "6a7e8feb-b491-4cf7-a9f1-bf3703467718",
  "detail-type": "EC2 Instance State-change Notification",
  "source": "aws.ec2",
  "account": "111122223333",
  "time": "2017-12-22T18:43:48Z",
  "region": "us-west-1",
  "resources": [
    "arn:aws:ec2:us-west-1:123456789012:instance/i-1234567890abcdef0"
  ],
  "detail": {
    "instance-id": "i-1234567890abcdef0",
    "state": "terminated"
  }
}
```

#### IBM - OpenWhisk - Web Action Event

```json
{
  "__ow_method": "post",
  "__ow_headers": {
    "accept": "*/*",
    "connection": "close",
    "content-length": "4",
    "content-type": "text/plain",
    "host": "172.17.0.1",
    "user-agent": "curl/7.43.0"
  },
  "__ow_path": "",
  "__ow_body": "Jane"
}
```

#### OpenStack - Audit Middleware - Event

```json
{
  "typeURI": "http://schemas.dmtf.org/cloud/audit/1.0/event",
  "id": "d8304637-3f63-5092-9ab3-18c9781871a2",
  "eventTime": "2018-01-30T10:46:16.740253+00:00",
  "action": "delete",
  "eventType": "activity",
  "outcome": "success",
  "reason": {
    "reasonType": "HTTP",
    "reasonCode": "204"
  },
  "initiator": {
    "typeURI": "service/security/account/user",
    "name": "user1",
    "domain": "domain1",
    "id": "52d28347f0b4cf9cc1717c00adf41c74cc764fe440b47aacb8404670a7cd5d22",
    "host": {
      "address": "127.0.0.1",
      "agent": "python-novaclient"
    },
    "project_id": "ae63ddf2076d4342a56eb049e37a7621"
  },
  "target": {
    "typeURI": "compute/server",
    "id": "b1b475fc-ef0a-4899-87f3-674ac0d56855"
  },
  "observer": {
    "typeURI": "service/compute",
    "name": "nova",
    "id": "1b5dbef1-c2e8-5614-888d-bb56bcf65749"
  },
  "requestPath": "/v2/ae63ddf2076d4342a56eb049e37a7621/servers/b1b475fc-ef0a-4899-87f3-674ac0d56855"
}
```

[Documentation](https://github.com/openstack/pycadf/blob/master/doc/source/event_concept.rst)

#### Adobe - I/O Events

```json
{
  "event_id": "639fd17a-d0bb-40ca-83a4-e78612bce5dc",
  "event": {
    "@id": "82235bac-2b81-4e70-90b5-2bd1f04b5c7b",
    "@type": "xdmCreated",
    "xdmEventEnvelope:objectType": "xdmAsset",
    "activitystreams:to": {
      "xdmImsUser:id": "D13A1E7053E46A220A4C86E1@AdobeID",
      "@type": "xdmImsUser"
    },
    "activitystreams:generator": {
      "xdmContentRepository:root": "https://cc-api-storage.adobe.io/",
      "@type": "xdmContentRepository"
    },
    "activitystreams:actor": {
      "xdmImsUser:id": "D13A1E7053E46A220A4C86E1@AdobeID",
      "@type": "xdmImsUser"
    },
    "activitystreams:object": {
      "@type": "xdmAsset",
      "xdmAsset:asset_id": "urn:aaid:sc:us:4123ba4c-93a8-4c5d-b979-ffbbe4318185",
      "xdmAsset:asset_name": "example.jpg",
      "xdmAsset:etag": "6fc55d0389d856ae7deccebba54f110e",
      "xdmAsset:path": "/MyFolder/example.jpg",
      "xdmAsset:format": "image/jpeg"
    },
    "activitystreams:published": "2016-07-16T19:20:30+01:00"
  }
}
```

[Documentation](https://www.adobe.io/apis/cloudplatform/events/documentation.html)
